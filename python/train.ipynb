{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubik's Cube Neural Solver - Colab Training\n",
    "\n",
    "This notebook allows you to train the neural network using Google Colab's GPU or TPU.\n",
    "It automatically clones the repository code so you can run it directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive (optional, for saving weights permanently)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Clone repository if modules are missing or to ensure freshness\n",
    "    if not os.path.exists('NeuroRubik'):\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/Kiwiabacaxi/NeuroRubik.git\n",
    "    else:\n",
    "        print(\"Repository already exists. Pulling latest changes...\")\n",
    "        %cd NeuroRubik\n",
    "        !git pull\n",
    "        %cd ..\n",
    "\n",
    "    # Add python directory to path\n",
    "    repo_path = '/content/NeuroRubik/python'\n",
    "    if repo_path not in sys.path:\n",
    "        sys.path.append(repo_path)\n",
    "    \n",
    "    # Change working directory to python folder so imports work relative to it\n",
    "    if os.path.exists(repo_path):\n",
    "        os.chdir(repo_path)\n",
    "        print(f\"Changed directory to {os.getcwd()}\")\n",
    "    \n",
    "    # Install requirements\n",
    "    !pip install -q tqdm\n",
    "    \n",
    "    # Note: We rely on pre-installed environment for TPU/GPU\n",
    "else:\n",
    "    # Local setup\n",
    "    if os.path.basename(os.getcwd()) != 'python':\n",
    "        if os.path.exists('python'):\n",
    "            os.chdir('python')\n",
    "        elif os.path.exists('../python'):\n",
    "            os.chdir('../python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Import Modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# DEVICE SENSING (GPU -> TPU -> CPU)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    # Try TPU (XLA)\n",
    "    try:\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        DEVICE = xm.xla_device()\n",
    "        print(f\"TPU Device Detected: {DEVICE}\")\n",
    "        print(\"\\033[91mWARNING: You are using TPU. For Genetic Algorithms (which have frequent CPU<->Accelerator transfers), TPU might be SLOWER than GPU.\")\n",
    "        print(\"RECOMMENDATION: Change Runtime type to 'T4 GPU' for faster performance on this specific task.\\033[0m\")\n",
    "    except ImportError:\n",
    "        print(\"WARNING: GPU not available and TPU libraries (torch_xla) not found.\")\n",
    "        print(\"Using CPU (Training will be slow).\")\n",
    "        DEVICE = torch.device('cpu')\n",
    "\n",
    "# Import project modules\n",
    "try:\n",
    "    from cube.cube_state import CubeState, MOVES\n",
    "    from genetic.evolution import GeneticAlgorithm\n",
    "    from genetic.individual import Individual\n",
    "    from genetic.fitness import BatchFitnessEvaluator\n",
    "    from neural.network import CubeSolverNetwork\n",
    "    from train import save_checkpoint, create_output_dir\n",
    "    print(\"Modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the repository is cloned and you are in the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Configuration\n",
    "# Training Parameters\n",
    "POPULATION = 1000 # @param {type:\"integer\"}\n",
    "GENERATIONS = 500 # @param {type:\"integer\"}\n",
    "ELITISM = 50 # @param {type:\"integer\"}\n",
    "MUTATION_RATE = 0.15 # @param {type:\"number\"}\n",
    "MUTATION_STRENGTH = 0.25 # @param {type:\"number\"}\n",
    "\n",
    "# Curriculum\n",
    "INITIAL_DEPTH = 1 # @param {type:\"integer\"}\n",
    "MAX_DEPTH = 20 # @param {type:\"integer\"}\n",
    "TEST_CUBES = 100 # @param {type:\"integer\"}\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_LAYERS = (512, 512, 512, 256, 128) # @param {type:\"raw\"}\n",
    "\n",
    "# Paths\n",
    "BASE_OUTPUT_DIR = \"/content/drive/MyDrive/CUBE/cube_weights\" # @param {type:\"string\"}\n",
    "\n",
    "# Resume Training (Optional)\n",
    "# Paste the full path to a checkpoint FOLDER (e.g., /content/drive/.../run_20260128_022005)\n",
    "# Leave empty to start fresh.\n",
    "LOAD_CHECKPOINT_PATH = \"/content/drive/MyDrive/CUBE/cube_weights/run_20260128_022005\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Initialize Training\n",
    "\n",
    "# Create Output Directory (with Versioning)\n",
    "try:\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    output_path = create_output_dir(BASE_OUTPUT_DIR)\n",
    "    print(f\"Saving new results to: {output_path}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory {BASE_OUTPUT_DIR}: {e}\")\n",
    "    print(\"Switching to local weights/ directory\")\n",
    "    BASE_OUTPUT_DIR = \"weights_colab\"\n",
    "    output_path = create_output_dir(BASE_OUTPUT_DIR)\n",
    "    print(f\"Saving results to: {output_path}\")\n",
    "\n",
    "# Initialize Network\n",
    "network = CubeSolverNetwork(hidden_sizes=HIDDEN_LAYERS, device=DEVICE)\n",
    "genome_size = network.get_weight_count()\n",
    "print(f\"Network created with {genome_size:,} weights\")\n",
    "\n",
    "# Initialize GA\n",
    "ga = GeneticAlgorithm(\n",
    "    population_size=POPULATION,\n",
    "    genome_size=genome_size,\n",
    "    mutation_rate=MUTATION_RATE,\n",
    "    mutation_strength=MUTATION_STRENGTH,\n",
    "    elitism_count=ELITISM\n",
    ")\n",
    "\n",
    "# Initialize Population (Always do this first)\n",
    "ga.initialize_population()\n",
    "\n",
    "# Load Checkpoint if specified\n",
    "current_generation_offset = 0\n",
    "best_fitness_loaded = 0.0\n",
    "\n",
    "if LOAD_CHECKPOINT_PATH:\n",
    "    checkpoint_file = os.path.join(LOAD_CHECKPOINT_PATH, \"checkpoint.json\")\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"Process resuming from: {checkpoint_file}\")\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "        \n",
    "        # Load Best Genome\n",
    "        best_genome = np.array(checkpoint[\"best_genome\"], dtype=np.float32)\n",
    "        best_fitness_loaded = checkpoint[\"best_fitness\"]\n",
    "        \n",
    "        # Inject into GA\n",
    "        ga.best_ever = Individual(genome=best_genome)\n",
    "        ga.best_ever.fitness = best_fitness_loaded\n",
    "        \n",
    "        # Seed population with best genome (Elitism)\n",
    "        # This ensures we don't start from zero, but still have variation\n",
    "        ga.population[0] = ga.best_ever.clone()\n",
    "        \n",
    "        # Restore training state\n",
    "        current_generation_offset = checkpoint.get(\"generation\", 0)\n",
    "        print(f\"Successfully loaded! Resuming from Gen {current_generation_offset} (Best Fitness: {best_fitness_loaded:.2f})\")\n",
    "        \n",
    "        # Try to restore curriculum depth if available\n",
    "        if \"evaluator\" in checkpoint:\n",
    "             INITIAL_DEPTH = checkpoint[\"evaluator\"].get(\"scramble_depth\", INITIAL_DEPTH)\n",
    "             print(f\"Restored Scramble Depth: {INITIAL_DEPTH}\")\n",
    "    else:\n",
    "        print(f\"WARNING: Checkpoint file not found at {checkpoint_file}. Starting fresh.\")\n",
    "\n",
    "# Initialize Evaluator\n",
    "evaluator = BatchFitnessEvaluator(\n",
    "    num_test_cubes=TEST_CUBES,\n",
    "    scramble_depth=INITIAL_DEPTH,\n",
    "    max_steps=50,\n",
    "    hidden_sizes=HIDDEN_LAYERS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "training_history = {\n",
    "    'fitness': [],\n",
    "    'depth': [],\n",
    "    'solved_rate': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Run Training Loop\n",
    "\n",
    "print(f\"Starting training for {GENERATIONS} generations...\")\n",
    "print(\"Tip: If progress takes too long to appear, you might be using TPU which is slow for this specific task due to data transfer overhead. Prefer T4 GPU.\")\n",
    "\n",
    "try:\n",
    "    # TQDM Progress Bar\n",
    "    pbar = tqdm(range(GENERATIONS), desc=\"Training\", unit=\"gen\")\n",
    "    \n",
    "    for i in pbar:\n",
    "        gen = current_generation_offset + i\n",
    "        ga.generation = gen\n",
    "\n",
    "        # Regenerate test cubes occasionally\n",
    "        if i % 5 == 0:\n",
    "            evaluator.regenerate_test_cubes()\n",
    "\n",
    "        # Evolve\n",
    "        ga.evolve_generation(evaluator)\n",
    "\n",
    "        # Stats\n",
    "        best = ga.population[0]\n",
    "        solve_rate = best.solved_count / TEST_CUBES\n",
    "        \n",
    "        # Update curriculum\n",
    "        depth_changed = evaluator.update_difficulty(solve_rate)\n",
    "        curriculum = evaluator.get_status()\n",
    "        current_depth = curriculum['current_depth']\n",
    "\n",
    "        # Store history\n",
    "        training_history['fitness'].append(best.fitness)\n",
    "        training_history['depth'].append(current_depth)\n",
    "        training_history['solved_rate'].append(solve_rate)\n",
    "        \n",
    "        # Update Progress Bar Text\n",
    "        pbar.set_postfix({\n",
    "            'Depth': current_depth,\n",
    "            'Best': f\"{best.fitness:.1f}\",\n",
    "            'Solved': f\"{best.solved_count}/{TEST_CUBES}\",\n",
    "            'Rate': f\"{solve_rate*100:.0f}%\"\n",
    "        })\n",
    "\n",
    "        # Visualization (Updates Graph)\n",
    "        if (i > 0 and i % 10 == 0) or depth_changed:\n",
    "            clear_output(wait=True)\n",
    "            # Re-display pbar after clear_output to keep it visible (Colab quirk)\n",
    "            display(pbar.container)\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Fitness Plot\n",
    "            ax1.plot(training_history['fitness'], label='Best Fitness', color='blue')\n",
    "            ax1.set_title(f'Gen {gen} - Fitness Progress')\n",
    "            ax1.set_xlabel('Generation')\n",
    "            ax1.set_ylabel('Fitness')\n",
    "            ax1.grid(True)\n",
    "            \n",
    "            # Curriculum Plot\n",
    "            ax2.plot(training_history['depth'], label='Scramble Depth', color='red')\n",
    "            ax2.set_title(f'Curriculum Level (Current: {current_depth})')\n",
    "            ax2.set_xlabel('Generation')\n",
    "            ax2.set_ylabel('Depth')\n",
    "            ax2.grid(True)\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        # Save Checkpoint\n",
    "        if i > 0 and i % 20 == 0:\n",
    "            save_checkpoint(ga, network, output_path, evaluator, HIDDEN_LAYERS)\n",
    "            \n",
    "        # TPU specific: Mark step to trigger execution\n",
    "        if 'xm' in globals():\n",
    "             try:\n",
    "                 import torch_xla.core.xla_model as xm\n",
    "                 xm.mark_step()\n",
    "             except Exception:\n",
    "                 pass\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted\")\n",
    "    \n",
    "# Final Save\n",
    "save_checkpoint(ga, network, output_path, evaluator, HIDDEN_LAYERS)\n",
    "print(f\"Done! saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
